{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a1ed5e",
   "metadata": {},
   "source": [
    "1) Initializing the notebook with all necessary parameters to use the model\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting. If you don’t specify a bucket, SageMaker SDK will create a default bucket following a pre-defined naming convention in the same region.\n",
    "\n",
    "- The IAM role ARN used to give SageMaker access to your data. It can be fetched using the get_execution_role method from sagemaker python SDK.\n",
    "\n",
    "- Also using automatic model tuning within this notebook to find the best version of the model by running many parallel jobs over a set range of hyperparameters.\n",
    "- Have the ability to change the range of all the parameter to you can choose a combination of values that optimize the model to get the accuracy you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e788baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::367379483300:role/service-role/AmazonSageMaker-ExecutionRole-20220712T124620\n",
      "a202990-mapping-osr-accounts-s3-bucket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "bucket = \"a202990-mapping-osr-accounts-s3-bucket\"\n",
    "print(bucket)\n",
    "prefix = \"Data10kCells\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce901e5b",
   "metadata": {},
   "source": [
    "- Retreive the data from the S3 bucket where it is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642240d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('s3://' + bucket + '/' + prefix + '/' + 'ActualDataWithoutExtraColumns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ada3bf",
   "metadata": {},
   "source": [
    "- Get all unique category names from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d0e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NCA 3 1 2 5'\n",
      " 'iXBRL DPL (cost of sales) other repairs and maintenance costs'\n",
      " 'NCA 3 2 2 5' ... 'iXBRL DPL (distribution) other staff costs, directors'\n",
      " 'NCA 7 3 2 2' 'Sales 1 UK']\n"
     ]
    }
   ],
   "source": [
    "categories = dataset[\"NominalCategoryCodename\"].unique()\n",
    "print(categories)\n",
    "with open(\"classes.txt\", 'w') as out:\n",
    "    for n in categories:\n",
    "        out.write(n + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb2157",
   "metadata": {},
   "source": [
    "- Labels each category name with a number for the model to mathematically calculate where the inputs go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497f4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = {}\n",
    "with open(\"classes.txt\") as f:\n",
    "   for i, label in enumerate(f.readlines()):\n",
    "        index_to_label[str(i + 1)] = label.strip()\n",
    "    \n",
    "#print(index_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d197c",
   "metadata": {},
   "source": [
    "2) Creating a dictionary for all the category names\n",
    "- What dataset.replace({parameter1 : dict_map}) does is that any input names that have the same name as the category aren't labeled as 1,1 but rather 1, (the name of the input).\n",
    "\n",
    "3) Using the NumPy function split() to create a three different datasets from the data. \n",
    "    - 70% will be used for training, 15% for testing and 15% for test validation\n",
    "    - Will create csv files that will contain this information to parse later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c744d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>Goodwill amortisation on foreign exchange movements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>iXBRL DPL (cost of sales) other repairs and ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Trademarks, patents and licenses amortisation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Motor vehicles depreciation eliminated on disp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Surplus or deficit on changes in fair value of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>iXBRL DPL F2 gain or loss on negative goodwill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9251</th>\n",
       "      <td>1153</td>\n",
       "      <td>Audit of the financial statements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9252</th>\n",
       "      <td>1154</td>\n",
       "      <td>iXBRL DPL (administrative) pension costs defin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>1155</td>\n",
       "      <td>iXBRL DPL (distribution) other staff costs, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>1156</td>\n",
       "      <td>Other depreciation charge for year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9255</th>\n",
       "      <td>1157</td>\n",
       "      <td>Sales 1 UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9255 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1 Goodwill amortisation on foreign exchange movements\n",
       "1        2  iXBRL DPL (cost of sales) other repairs and ma... \n",
       "2        3  Trademarks, patents and licenses amortisation ... \n",
       "3        4  Motor vehicles depreciation eliminated on disp... \n",
       "4        5  Surplus or deficit on changes in fair value of... \n",
       "5        6  iXBRL DPL F2 gain or loss on negative goodwill... \n",
       "...    ...                                                ... \n",
       "9251  1153                  Audit of the financial statements \n",
       "9252  1154  iXBRL DPL (administrative) pension costs defin... \n",
       "9253  1155  iXBRL DPL (distribution) other staff costs, di... \n",
       "9254  1156                 Other depreciation charge for year \n",
       "9255  1157                                         Sales 1 UK \n",
       "\n",
       "[9255 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_map = {v: k for k, v in index_to_label.items()}\n",
    "#data = dataset.replace(dict_map)\n",
    "data = dataset.replace({\"NominalCategoryCodename\": dict_map})\n",
    "data = data.rename(columns = data.iloc[0]).drop(data.index[0])\n",
    "#data = data.rename(columns = data.iloc[0])\n",
    "#data.iloc[1] = \"Name\"\n",
    "#data = data.rename(columns = data.iloc[1])\n",
    "\n",
    "#Train Test Split\n",
    "train_data, validation_data, test_data = np.split(data.sample(frac = 1, random_state = 2000), [int(.7 * len(data)), int(.85 * len(data))])\n",
    "train_data.to_csv(\"train.csv\", header = True, index = False)\n",
    "validation_data.to_csv('test.csv', header = True, index = False)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1d63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_csv('trainwithoutrow[1]10kcells.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12eb76c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       218\n",
      "1       478\n",
      "2       409\n",
      "3       350\n",
      "4       186\n",
      "       ... \n",
      "6473    358\n",
      "6474    889\n",
      "6475    819\n",
      "6476     82\n",
      "6477    864\n",
      "Name: 1, Length: 6478, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset2['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4201418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Shows us the frequency of each category within the Train.csv file\n",
    "x = plt.hist(dataset2['1'],bins = 2000)\n",
    "plt.show(x)\n",
    "#for s in a:\n",
    "  #  if dataset[\"Names\"][s] != 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908f83d",
   "metadata": {},
   "source": [
    "4) BlazingText expects a single preprocessed text file with space separated tokens and each line of the file should contain a single sentence and the corresponding label(s) prefixed by “_*label_*”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46db5c7",
   "metadata": {},
   "source": [
    "- We need to preprocess the training data into space separated tokenized text format which can be consumed by BlazingText algorithm. Also, as mentioned previously, the class label(s) should be prefixed with __label__ and it should be present in the same line along with the original sentence. We’ll use nltk library to tokenize the input sentences from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a80826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_instance(row):\n",
    "    cur_row = []\n",
    "    label = \"__label__\" + index_to_label[row[0]]  # Prefix the index-ed label with __label__\n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row[1].lower()))\n",
    "    #cur_row.extend(nltk.word_tokenize(row[2].lower()))\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed426b24",
   "metadata": {},
   "source": [
    "The transform_instance will be applied to each data instance in parallel using python’s multiprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4e304f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_file, output_file, keep = 1):\n",
    "    all_rows = []\n",
    "    with open(input_file, \"r\") as csvinfile:\n",
    "        csv_reader = csv.reader(csvinfile, delimiter=\",\")\n",
    "        for row in csv_reader:\n",
    "            all_rows.append(row)\n",
    "    shuffle(all_rows)\n",
    "    all_rows = all_rows[: int(keep * len(all_rows))]\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "    transformed_rows = pool.map(transform_instance, all_rows)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    with open(output_file, \"w\") as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=\" \", lineterminator=\"\\n\")\n",
    "        csv_writer.writerows(transformed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75fcae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 133 ms, sys: 101 ms, total: 233 ms\n",
      "Wall time: 914 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Preparing the training dataset\n",
    "\n",
    "# Since preprocessing the whole dataset might take a couple of mintutes,\n",
    "# we keep 20% of the training dataset for this demo.\n",
    "# Set keep to 1 if you want to use the complete dataset\n",
    "preprocess(\"train.csv\", \"categories.train\", keep=1)\n",
    "\n",
    "# Preparing the validation dataset\n",
    "preprocess(\"test.csv\", \"categories.validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e83a0b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.3 ms, sys: 11 ms, total: 61.4 ms\n",
      "Wall time: 357 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + \"/train\"\n",
    "validation_channel = prefix + \"/validation\"\n",
    "\n",
    "sess.upload_data(path=\"categories.train\", bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path=\"categories.validation\", bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = \"s3://{}/{}\".format(bucket, train_channel)\n",
    "s3_validation_data = \"s3://{}/{}\".format(bucket, validation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20ac58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = \"s3://{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ff3ba",
   "metadata": {},
   "source": [
    "5) Training the BlazingText model for Supervised Text Classification and settings up Hyperparemeter Tuning Job\n",
    "\n",
    "- Now that we are done with all the setup that is needed, we are ready to train our object detector. To begin, let us create a sageMaker.estimator.Estimator object. This estimator will launch the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "988e8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8395c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:1 (us-east-1)\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"1\")\n",
    "print(\"Using SageMaker BlazingText container: {} ({})\".format(container, region_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038fd30",
   "metadata": {},
   "source": [
    "6) Now, let’s define the SageMaker Estimator with resource configurations and hyperparameters to train Text Classification on the  dataset, using “supervised” mode on a ml.c4.4xlarge instance.\n",
    "\n",
    "- Refer to BlazingText Hyperparameters in the Amazon SageMaker documentation for the complete list of hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61db8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.4xlarge\",\n",
    "    volume_size=30,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters={\n",
    "        \"mode\": \"supervised\",\n",
    "        \"epochs\": 25,\n",
    "        \"min_count\": 2,\n",
    "        #\"learning_rate\": 0.05,\n",
    "        #\"vector_dim\": 10,\n",
    "        \"early_stopping\": True,\n",
    "        \"patience\": 4,\n",
    "        \"min_epochs\": 5,\n",
    "        \"word_ngrams\": 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c59dff",
   "metadata": {},
   "source": [
    "7) Setting up Hyperparameter tuning here\n",
    "- Setting our hyperparameter ranges here. If you want to improve accuracy after running the model, you can change the ranged here to create a larger range of testing. \n",
    "- Note it will take much longer with a larger range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1681a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.05, 0.15),\n",
    "    \"vector_dim\": IntegerParameter(32, 300),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb8c7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"validation:accuracy\"\n",
    "objective_type = \"Maximize\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c790675",
   "metadata": {},
   "source": [
    "8) Create a HyperparameterTuner object, to which we pass:\n",
    "\n",
    "-  The BlazingText estimator we created above\n",
    "-  Our hyperparameter ranges\n",
    "-  Objective metric name and definition\n",
    "-  Tuning resource configurations such as Number of training jobs to run in total and how many training jobs can be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b2b0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a63346b",
   "metadata": {},
   "source": [
    "9) Now that the hyper-parameters are setup, let us prepare the connection between our data channels and the algorithm. To do this, we need to create the sagemaker.session.s3_input objects from our data channels. These objects are then put in a simple dictionary, which the algorithm consumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f459699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cebe083",
   "metadata": {},
   "source": [
    "- We have our Estimator object, we have set the hyper-parameters for this object and we have our data channels linked with the algorithm. The only remaining thing to do is to train the algorithm. The following command will train the algorithm. Training the algorithm involves a few steps. Firstly, the instance that we requested while creating the Estimator classes is provisioned and is setup with the appropriate libraries. Then, the data from our channels are downloaded into the instance. Once this is done, the training job begins. The provisioning and data downloading will take some time, depending on the size of the data. Therefore it might be a few minutes before we start getting training logs for our training jobs. The data logs will also print out Accuracy on the validation data for every epoch after training job has executed min_epochs. This metric is a proxy for the quality of the algorithm.\n",
    "\n",
    "- Once the job has finished a “Job complete” message will be printed. The trained model can be found in the S3 bucket that was setup as output_path in the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1365bfa",
   "metadata": {},
   "source": [
    "10) Launch the Hyperparameter tuning job\n",
    "\n",
    "- Use the fit() method to launch the job and use the SageMaker Console to keep track of progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "698416c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................!\n",
      "CPU times: user 634 ms, sys: 47.8 ms, total: 682 ms\n",
      "Wall time: 9min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tuner.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186ee1a",
   "metadata": {},
   "source": [
    "- Analyze + Track The tuning Job Results and Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29c6596c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blazingtext-220811-1702'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "tuning_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffa66f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 training jobs have completed\n"
     ]
    }
   ],
   "source": [
    "tuning_job_result = sm_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")\n",
    "\n",
    "status = tuning_job_result[\"HyperParameterTuningJobStatus\"]\n",
    "if status != \"Completed\":\n",
    "    print(\"Reminder: the tuning job has not been completed.\")\n",
    "\n",
    "job_count = tuning_job_result[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "print(\"%d training jobs have completed\" % job_count)\n",
    "\n",
    "is_minimize = (\n",
    "    tuning_job_result[\"HyperParameterTuningJobConfig\"][\"HyperParameterTuningJobObjective\"][\"Type\"]\n",
    "    != \"Maximize\"\n",
    ")\n",
    "objective_name = tuning_job_result[\"HyperParameterTuningJobConfig\"][\n",
    "    \"HyperParameterTuningJobObjective\"\n",
    "][\"MetricName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebd135b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found so far:\n",
      "{'CreationTime': datetime.datetime(2022, 8, 11, 17, 8, 57, tzinfo=tzlocal()),\n",
      " 'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'validation:accuracy',\n",
      "                                                 'Value': 0.875},\n",
      " 'ObjectiveStatus': 'Succeeded',\n",
      " 'TrainingEndTime': datetime.datetime(2022, 8, 11, 17, 11, 37, tzinfo=tzlocal()),\n",
      " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:367379483300:training-job/blazingtext-220811-1702-006-04edb2c2',\n",
      " 'TrainingJobName': 'blazingtext-220811-1702-006-04edb2c2',\n",
      " 'TrainingJobStatus': 'Completed',\n",
      " 'TrainingStartTime': datetime.datetime(2022, 8, 11, 17, 10, 50, tzinfo=tzlocal()),\n",
      " 'TunedHyperParameters': {'learning_rate': '0.15', 'vector_dim': '32'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "if tuning_job_result.get(\"BestTrainingJob\", None):\n",
    "    print(\"Best model found so far:\")\n",
    "    pprint(tuning_job_result[\"BestTrainingJob\"])\n",
    "else:\n",
    "    print(\"No training jobs have reported results yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8908c8",
   "metadata": {},
   "source": [
    "- Get the results and make it a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef947288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training jobs with valid objective: 6\n",
      "{'lowest': 0.0625, 'highest': 0.875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9256/3842159511.py:13: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"display.max_colwidth\", -1)  # Don't truncate TrainingJobName\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>vector_dim</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>blazingtext-220811-1702-006-04edb2c2</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>2022-08-11 17:10:50+00:00</td>\n",
       "      <td>2022-08-11 17:11:37+00:00</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142609</td>\n",
       "      <td>104.0</td>\n",
       "      <td>blazingtext-220811-1702-003-8deb94bb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>2022-08-11 17:07:34+00:00</td>\n",
       "      <td>2022-08-11 17:08:26+00:00</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129399</td>\n",
       "      <td>95.0</td>\n",
       "      <td>blazingtext-220811-1702-005-8da03655</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>2022-08-11 17:10:41+00:00</td>\n",
       "      <td>2022-08-11 17:11:33+00:00</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129569</td>\n",
       "      <td>69.0</td>\n",
       "      <td>blazingtext-220811-1702-002-75fc8cd0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>2022-08-11 17:04:43+00:00</td>\n",
       "      <td>2022-08-11 17:05:30+00:00</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.115211</td>\n",
       "      <td>34.0</td>\n",
       "      <td>blazingtext-220811-1702-001-a41b5be6</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>2022-08-11 17:04:34+00:00</td>\n",
       "      <td>2022-08-11 17:05:30+00:00</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084502</td>\n",
       "      <td>257.0</td>\n",
       "      <td>blazingtext-220811-1702-004-e6e6d455</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>2022-08-11 17:07:41+00:00</td>\n",
       "      <td>2022-08-11 17:08:33+00:00</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  vector_dim                       TrainingJobName  \\\n",
       "0  0.150000       32.0        blazingtext-220811-1702-006-04edb2c2   \n",
       "3  0.142609       104.0       blazingtext-220811-1702-003-8deb94bb   \n",
       "1  0.129399       95.0        blazingtext-220811-1702-005-8da03655   \n",
       "4  0.129569       69.0        blazingtext-220811-1702-002-75fc8cd0   \n",
       "5  0.115211       34.0        blazingtext-220811-1702-001-a41b5be6   \n",
       "2  0.084502       257.0       blazingtext-220811-1702-004-e6e6d455   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0  Completed         0.8750              2022-08-11 17:10:50+00:00   \n",
       "3  Completed         0.8125              2022-08-11 17:07:34+00:00   \n",
       "1  Completed         0.6875              2022-08-11 17:10:41+00:00   \n",
       "4  Completed         0.6875              2022-08-11 17:04:43+00:00   \n",
       "5  Completed         0.5625              2022-08-11 17:04:34+00:00   \n",
       "2  Completed         0.0625              2022-08-11 17:07:41+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0 2022-08-11 17:11:37+00:00  47.0                        \n",
       "3 2022-08-11 17:08:26+00:00  52.0                        \n",
       "1 2022-08-11 17:11:33+00:00  52.0                        \n",
       "4 2022-08-11 17:05:30+00:00  47.0                        \n",
       "5 2022-08-11 17:05:30+00:00  56.0                        \n",
       "2 2022-08-11 17:08:33+00:00  52.0                        "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tuner_analytics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "\n",
    "full_df = tuner_analytics.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values(\"FinalObjectiveValue\", ascending=is_minimize)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\": min(df[\"FinalObjectiveValue\"]), \"highest\": max(df[\"FinalObjectiveValue\"])})\n",
    "        pd.set_option(\"display.max_colwidth\", -1)  # Don't truncate TrainingJobName\n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d02e5c",
   "metadata": {},
   "source": [
    "11) Hosting / Inference the best trained model\n",
    "\n",
    "- Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint. This will allow us to make predictions (or inference) from the model. Note that we don’t have to host on the same type of instance that we used to train. Because instance endpoints will be up and running for long, it’s advisable to choose a cheaper instance for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75f71940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-11 17:11:37 Starting - Preparing the instances for training\n",
      "2022-08-11 17:11:37 Downloading - Downloading input data\n",
      "2022-08-11 17:11:37 Training - Training image download completed. Training in progress.\n",
      "2022-08-11 17:11:37 Uploading - Uploading generated training model\n",
      "2022-08-11 17:11:37 Completed - Training job completed\n",
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "text_classifier = tuner.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m4.xlarge\", serializer=JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc95fc",
   "metadata": {},
   "source": [
    "- BlazingText supports application/json as the content-type for inference. The payload should contain a list of sentences with the key as “instances” while being passed to the endpoint.\n",
    "\n",
    "- By default, the model will return only one prediction, the one with the highest probability. For retrieving the top k predictions, you can set k in the configuration as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c40db40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__PBT\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.4981212615966797\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentences = {\n",
    "    #\"Vehicle Costs for Crash\"\n",
    "    #\"Current Liabilities\"\n",
    "    #\"Financial Contracts\"\n",
    "    #\"Other country Money\"\n",
    "    #\"Government\" \n",
    "    #\"iXBRL DPL F2 gain or loss on negative goodwill/bargain purchases released to income\"\n",
    "    #\"Contract liabilities\"\n",
    "    #\"Miscellaneous other operating income\"\n",
    "    #\"Current portion of long term lease liabilities\"\n",
    "    #\"iXBRL DPL (cost of sales) wages/salaries\"\n",
    "    #\"Gain or loss on disposal of property, plant and equipment\"\n",
    "    #\"Deferred tax on post-retirement healthcare scheme 1 asset/liability\"\n",
    "    #\"Balance\"\n",
    "    'Profit/loss before tax' #50% probability but 100% accuracy\n",
    "    #'Current assets' #54% probability with 100% accuracy\n",
    "    #'Other current financial liabilities' # 53% probability with 100% accuracy\n",
    "    \n",
    "    \n",
    "    ##Major Problem with NLP is that it can't understand accounting terminology like a human can unless we train it over and over again\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "tokenized_sentences = [\" \".join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "payload = {\"instances\": tokenized_sentences}\n",
    "\n",
    "response = text_classifier.predict(payload)\n",
    "\n",
    "predictions = json.loads(response)\n",
    "\n",
    "print(json.dumps(predictions, indent=2))\n",
    "#print(\"prob: 100%\")\n",
    "\n",
    "#runtime_client = boto3.client(\"runtime.sagemaker\", region_name = region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a5b48",
   "metadata": {},
   "source": [
    "12) Delete Endpoints\n",
    "\n",
    "- Finally, we should delete the endpoint before we close the notebook if we don’t need to keep the endpoint running for serving realtime predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "522e3091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(text_classifier.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475cc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
